{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474374cd",
   "metadata": {},
   "source": [
    "### Custom FaceSwap from scratch with dlib and opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5744c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b1eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector and predictor for faces in images\n",
    "frontal_face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Using a pretrained model for face landmark points\n",
    "frontal_face_detector = dlib.shape_predictor(\"dataset/shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d711de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read src and dest images and covert to grayscale\n",
    "src_img = cv2.imread('images/ayobami.jpg')\n",
    "src_img_ = src_img\n",
    "src_imgGrey = cv2.cvtColor(src_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "dest_img = cv2.imread('images/ayodeji.jpg')\n",
    "dest_img_ = dest_img\n",
    "dest_imgGrey = cv2.cvtColor(dest_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Display the images\n",
    "cv2.imshow('Ayobami', src_img)\n",
    "cv2.imshow('Ayodeji', dest_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5362541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 1000, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83db711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zeros arrays canvas with th sam esize of source image gra\n",
    "source_image_canvas = np.zeros_like(source_image_gray)\n",
    "\n",
    "# Get image of desination image\n",
    "height, width, channels = dest_image.shape\n",
    "\n",
    "# Create zero arry canvas like dest image\n",
    "dest_image_canvas =  np.zeros_like((dest_image), np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86aef6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faceRect = frontal_face_detector.rect\n",
    "# landmarks = shape_to_np(predictor(gray, faceRect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1abe6cb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.shape_predictor, image: array, box: _dlib_pybind11.rectangle) -> _dlib_pybind11.full_object_detection\n\nInvoked with: <_dlib_pybind11.shape_predictor object at 0x0000019CB8752DF0>, array([[25, 25, 25, ..., 56, 56, 57],\n       [25, 25, 26, ..., 56, 57, 57],\n       [25, 25, 26, ..., 57, 58, 58],\n       ...,\n       [29, 29, 30, ..., 27, 28, 28],\n       [29, 29, 29, ..., 28, 28, 28],\n       [30, 29, 29, ..., 28, 28, 28]], dtype=uint8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-17f8df23e730>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# # Find the faces in source image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# frontal_face_det\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msource_faces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_image_gray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msource_image_gray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.shape_predictor, image: array, box: _dlib_pybind11.rectangle) -> _dlib_pybind11.full_object_detection\n\nInvoked with: <_dlib_pybind11.shape_predictor object at 0x0000019CB8752DF0>, array([[25, 25, 25, ..., 56, 56, 57],\n       [25, 25, 26, ..., 56, 57, 57],\n       [25, 25, 26, ..., 57, 58, 58],\n       ...,\n       [29, 29, 30, ..., 27, 28, 28],\n       [29, 29, 29, ..., 28, 28, 28],\n       [30, 29, 29, ..., 28, 28, 28]], dtype=uint8)"
     ]
    }
   ],
   "source": [
    "# # Find the faces in source image\n",
    "# frontal_face_det\n",
    "source_faces = frontal_face_detector(source_image_gray)\n",
    "source_image_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7704340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "\n",
    "#initialize dlib library's face detector\n",
    "#create dlib library's facial landmark predictor\n",
    "frontal_face_detector = dlib.get_frontal_face_detector()\n",
    "frontal_face_predictor = dlib.shape_predictor(\"dataset/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "#read the source face image and convert it to grayscale\n",
    "source_image = cv2.imread(\"images/ayobami.jpg\")\n",
    "source_image_grayscale = cv2.cvtColor(source_image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"source_image\",source_image)\n",
    "\n",
    "#read the destination face image and convert it to grayscale\n",
    "destination_image = cv2.imread(\"images/ayodeji.jpg\")\n",
    "destination_image_grayscale = cv2.cvtColor(destination_image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"destination_image\",destination_image)\n",
    "\n",
    "#create a zeros array canvas exactly like the same size of source_image_grayscale\n",
    "source_image_canvas = np.zeros_like(source_image_grayscale)\n",
    "\n",
    "#getting the shape of destination_image\n",
    "height, width, no_of_channels = destination_image.shape\n",
    "\n",
    "#create a zeros array canvas like the destination image\n",
    "destination_image_canvas = np.zeros((height,width,no_of_channels),np.uint8)\n",
    "\n",
    "#define a method to get the index\n",
    "def index_from_array(numpyarray):\n",
    "    index = None\n",
    "    for n in numpyarray[0]:\n",
    "        index = n\n",
    "        break\n",
    "    return index\n",
    "\n",
    "\n",
    "#FOR THE SOURCE IMAGE\n",
    "####################\n",
    "#Find the faces in source image\n",
    "#Returns a numpy array containing a histogram of pixels in the image\n",
    "source_faces = frontal_face_detector(source_image_grayscale)\n",
    "\n",
    "#loop through all faces found in the source image\n",
    "for source_face in source_faces:\n",
    "    #predictor takes human face as input and returns the list of facial landmarks\n",
    "    source_face_landmarks = frontal_face_predictor(source_image_grayscale, source_face)\n",
    "    source_face_landmark_points = []\n",
    "    \n",
    "    #loop through all the 68 landmark points \n",
    "    #add them into a tuple\n",
    "    for landmark_no in range(0,68):\n",
    "        x_point = source_face_landmarks.part(landmark_no).x\n",
    "        y_point = source_face_landmarks.part(landmark_no).y\n",
    "        source_face_landmark_points.append((x_point, y_point))\n",
    "        # #just for demo\n",
    "        # cv2.circle(source_image,(x_point,y_point),2,(255,255,0),-1)\n",
    "        # cv2.putText(source_image, str(landmark_no), (x_point,y_point), cv2.FONT_HERSHEY_SIMPLEX, .3, (255,255,255))\n",
    "        # cv2.imshow(\"1: landmark points of source\",source_image)\n",
    "\n",
    "    #converting the points into a numpy array\n",
    "    source_face_landmark_points_array = np.array(source_face_landmark_points,np.int32)\n",
    "    #find the convex hull of the face, the contour points\n",
    "    source_face_convexhull = cv2.convexHull(source_face_landmark_points_array)\n",
    "    # #for demo\n",
    "    # cv2.polylines(source_image, [source_face_convexhull], True, (255,0,0),1)\n",
    "    # cv2.imshow(\"2: convex hull of source image face\",source_image)\n",
    "    \n",
    "    #draw a filled polygon over the zero array canvas of source\n",
    "    cv2.fillConvexPoly(source_image_canvas, source_face_convexhull, 255)\n",
    "    #cv2.imshow(\"3: draw the convexhull polygon over canvas\", source_image_canvas)\n",
    "    \n",
    "    #place the created mask over the source image\n",
    "    source_face_image = cv2.bitwise_and(source_image,source_image,mask=source_image_canvas)\n",
    "    #cv2.imshow(\"4: place mask over source image\", source_face_image)\n",
    "\n",
    "#Delaunay Triangulation of Source Image Steps\n",
    "#############################################\n",
    "    #Drawing an approximate bounding rectangle around the face convex hull\n",
    "    bounding_rectangle = cv2.boundingRect(source_face_convexhull)\n",
    "\n",
    "    #create an empty Delaunay subdivision\n",
    "    subdivisions = cv2.Subdiv2D(bounding_rectangle)\n",
    "    #insert the face landmark points into subdivisions\n",
    "    subdivisions.insert(source_face_landmark_points)\n",
    "    #will return triangles list as 6 numbered vectors\n",
    "    triangles_vector = subdivisions.getTriangleList()\n",
    "    #convert vector into numpy array\n",
    "    triangles_array = np.array(triangles_vector,dtype=np.int32)\n",
    "    \n",
    "    #print(triangles_array)\n",
    "    source_triangle_index_points_list = []\n",
    "    \n",
    "    for triangle in triangles_array:\n",
    "        index_point1 = (triangle[0], triangle[1])\n",
    "        index_point2 = (triangle[2], triangle[3])\n",
    "        index_point3 = (triangle[4], triangle[5])\n",
    "        \n",
    "        # line_color = (255,0,0)\n",
    "        # cv2.line(source_face_image, index_point1, index_point2, line_color, 1 )\n",
    "        # cv2.line(source_face_image, index_point2, index_point3, line_color, 1 )\n",
    "        # cv2.line(source_face_image, index_point3, index_point1, line_color, 1 )\n",
    "        \n",
    "        # cv2.imshow(\"5: Drawing all Delaunay triangles in source image \", source_face_image)\n",
    "\n",
    "        #convert the co-ordinates into facial landmark references\n",
    "        index_point1 = np.where((source_face_landmark_points_array == index_point1).all(axis=1))\n",
    "        index_point1 = index_from_array(index_point1)\n",
    "        index_point2 = np.where((source_face_landmark_points_array == index_point2).all(axis=1))\n",
    "        index_point2 = index_from_array(index_point2)\n",
    "        index_point3 = np.where((source_face_landmark_points_array == index_point3).all(axis=1))\n",
    "        index_point3 = index_from_array(index_point3)\n",
    "        \n",
    "        triangle = [index_point1, index_point2, index_point3]\n",
    "        source_triangle_index_points_list.append(triangle)\n",
    "        \n",
    "#print(triangle_index_points_list)\n",
    "   \n",
    "#FOR THE DESTINATION IMAGE\n",
    "##########################\n",
    "#Find the faces in destination image\n",
    "#Returns a numpy array containing a histogram of pixels in the image\n",
    "destination_faces = frontal_face_detector(destination_image_grayscale)\n",
    "\n",
    "#loop through all faces found in the destination image\n",
    "for destination_face in destination_faces:\n",
    "    #predictor takes human face as input and returns the list of facial landmarks\n",
    "    destination_face_landmarks = frontal_face_predictor(destination_image_grayscale, destination_face)\n",
    "    destination_face_landmark_points = []\n",
    "    \n",
    "    #loop through all the 68 landmark points \n",
    "    #add them into a tuple\n",
    "    for landmark_no in range(0,68):\n",
    "        x_point = destination_face_landmarks.part(landmark_no).x\n",
    "        y_point = destination_face_landmarks.part(landmark_no).y\n",
    "        destination_face_landmark_points.append((x_point, y_point))\n",
    "        #just for demo\n",
    "        # cv2.circle(destination_image,(x_point,y_point),2,(255,255,0),-1)\n",
    "        # cv2.putText(destination_image, str(landmark_no), (x_point,y_point), cv2.FONT_HERSHEY_SIMPLEX, .3, (255,255,255))\n",
    "        # cv2.imshow(\"1: landmark points of destination\",destination_image)\n",
    "\n",
    "    #converting the points into a numpy array\n",
    "    destination_face_landmark_points_array = np.array(destination_face_landmark_points,np.int32)\n",
    "    #find the convex hull of the face, the contour points\n",
    "    destination_face_convexhull = cv2.convexHull(destination_face_landmark_points_array)\n",
    "    #for demo\n",
    "    # cv2.polylines(destination_image, [destination_face_convexhull], True, (255,0,0),1)\n",
    "    # cv2.imshow(\"2: convex hull of destination image face\",destination_image)\n",
    "    \n",
    "\n",
    "for i, triangle_index_points in enumerate(source_triangle_index_points_list):\n",
    "    \n",
    "    #for every source triangle from the list of triangles,\n",
    "    #crop the bounding rectangle and extract only triangle points.\n",
    "    #################################################################\n",
    "    #get x and y coordinates of the vertices\n",
    "    source_triangle_point1 = source_face_landmark_points[triangle_index_points[0]]\n",
    "    source_triangle_point2 = source_face_landmark_points[triangle_index_points[1]]\n",
    "    source_triangle_point3 = source_face_landmark_points[triangle_index_points[2]]\n",
    "    #combining the three points into a numpy array\n",
    "    source_triangle = np.array([source_triangle_point1,source_triangle_point2,source_triangle_point3], np.int32)\n",
    "    \n",
    "    #draw bounding rectangle around the triangle points and crop it for later use\n",
    "    source_rectangle = cv2.boundingRect(source_triangle)\n",
    "    (x,y,w,h) = source_rectangle\n",
    "    cropped_source_rectangle = source_image[y:y+h, x:x+w]\n",
    "    \n",
    "    #remove rectangle points and keep the triangle points only for later use\n",
    "    source_triangle_points = np.array([[source_triangle_point1[0] - x, source_triangle_point1[1] - y],\n",
    "                                       [source_triangle_point2[0] - x, source_triangle_point2[1] - y],\n",
    "                                       [source_triangle_point3[0] - x, source_triangle_point3[1]- y]], np.int32)\n",
    "                                      \n",
    "    #for demo, select triangle 10\n",
    "    # if i==10:\n",
    "    #     #display triangle lines in white, rectangle in red\n",
    "    #     cv2.line(source_image,source_triangle_point1,source_triangle_point2, (255,255,255))\n",
    "    #     cv2.line(source_image,source_triangle_point2,source_triangle_point3, (255,255,255))\n",
    "    #     cv2.line(source_image,source_triangle_point3,source_triangle_point1, (255,255,255))\n",
    "    #     cv2.imshow('8.1 Source Triangle Lines', source_image)\n",
    "    #     cv2.rectangle(source_image, (x,y), (x+w,y+h), (0,0,255))\n",
    "    #     cv2.imshow('8.2 Source Rectangle Lines', source_image)\n",
    "    #     cv2.imshow('8.3 Cropped Source Rectangle', cropped_source_rectangle)\n",
    "\n",
    "\n",
    "    #for every destination triangle from the list of triangles,\n",
    "    #extract only triangle points and create a mask with the triangle.\n",
    "    #################################################################\n",
    "    #get x and y coordinates of the vertices\n",
    "    destination_triangle_point1 = destination_face_landmark_points[triangle_index_points[0]]\n",
    "    destination_triangle_point2 = destination_face_landmark_points[triangle_index_points[1]]\n",
    "    destination_triangle_point3 = destination_face_landmark_points[triangle_index_points[2]]\n",
    "    destination_triangle = np.array([destination_triangle_point1, destination_triangle_point2, destination_triangle_point3], np.int32)\n",
    "    \n",
    "    #Draw Bounding Rectangle around the triangle\n",
    "    destination_rectangle = cv2.boundingRect(destination_triangle)\n",
    "    (x, y, w, h) = destination_rectangle\n",
    "    \n",
    "    \n",
    "    #crop destination rectangle and create a mask  for later use        \n",
    "    cropped_destination_rectangle = source_image[h,w]\n",
    "    cropped_destination_rectangle_mask = np.zeros((h, w), np.uint8)\n",
    "    \n",
    "    #remove the rectangle points to obtain only the triangle points for later use\n",
    "    destination_triangle_points = np.array([[destination_triangle_point1[0] - x, destination_triangle_point1[1] - y],\n",
    "                       [destination_triangle_point2[0] - x, destination_triangle_point2[1] - y],\n",
    "                       [destination_triangle_point3[0] - x, destination_triangle_point3[1] - y]], np.int32)\n",
    "\n",
    "    # triangle points over the cropped rectangle zero array mask\n",
    "    cv2.fillConvexPoly(cropped_destination_rectangle_mask, destination_triangle_points, 255)\n",
    "\n",
    "    #for demo, select triangle 10\n",
    "    # if i==10:\n",
    "    #     cv2.line(destination_image,destination_triangle_point1,destination_triangle_point2, (255,255,255), 1)\n",
    "    #     cv2.line(destination_image,destination_triangle_point2,destination_triangle_point3, (255,255,255), 1)\n",
    "    #     cv2.line(destination_image,destination_triangle_point3,destination_triangle_point1, (255,255,255), 1)\n",
    "    #     cv2.imshow(\"9.1: Destination Triangle Lines\", destination_image)        \n",
    "    #     cv2.rectangle(destination_image,(x,y),(x+w,y+h), (0,0,255), 1)\n",
    "    #     cv2.imshow(\"9.2: Destination rectangle Lines\", destination_image)\n",
    "    #     cv2.imshow(\"9.3: Destination filled rectangle mask\", cropped_destination_rectangle_mask)\n",
    "\n",
    "    #warp source triangles to match the destination triangle shape\n",
    "    #and place destination triangle mask over it    \n",
    "    ############################################\n",
    "    #converting to numpy array\n",
    "    source_triangle_points = np.float32(source_triangle_points)\n",
    "    destination_triangle_points = np.float32(destination_triangle_points)\n",
    "    #creating the transformation matrix for warp affine method\n",
    "    Matrix = cv2.getAffineTransform(source_triangle_points, destination_triangle_points)\n",
    "    #creating the warped triangle\n",
    "    warped_triangle = cv2.warpAffine(cropped_source_rectangle, Matrix, (w,h))\n",
    "    #for demo, select triangle 10\n",
    "    # if i==10:\n",
    "    #     cv2.imshow(\"10.1: warped source triangle wrt the destination triangle points\",warped_triangle)\n",
    "    #placing destination rectangle mask over the warped triangle\n",
    "    warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=cropped_destination_rectangle_mask)\n",
    "    #for demo, select triangle 10\n",
    "    # if i==10:\n",
    "    #     cv2.imshow(\"10.2: warped source triangle with the mask\",warped_triangle)\n",
    "\n",
    "    #reconstructing destination face in an empty canvas the size of destination image\n",
    "    ##################################################################################  \n",
    "    #steps to cut off the white lines in the triangle using a mask\n",
    "    #small rectangular slice of destination canvas in the shape of warped rectange\n",
    "    new_dest_face_canvas_area = destination_image_canvas[y: y+h, x: x+w]\n",
    "    #convert the new small canvas to grayscale\n",
    "    new_dest_face_canvas_area_gray = cv2.cvtColor(new_dest_face_canvas_area, cv2.COLOR_BGR2GRAY)\n",
    "    #creating a mask to cut the pixels inside triangle excluding the white lines\n",
    "    _, mask_created_triangle = cv2.threshold(new_dest_face_canvas_area_gray, 1, 255, cv2.THRESH_BINARY_INV)\n",
    "    #placing the mask created\n",
    "    wraped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask = mask_created_triangle)\n",
    "    #place the masked triangle inside the small canvas area\n",
    "    new_dest_face_canvas_area = cv2.add(new_dest_face_canvas_area, wraped_triangle)\n",
    "    #place the new small canvas with triangle in it to the large destination canvas\n",
    "    #at the designated location\n",
    "    destination_image_canvas[y: y+h, x: x+w] = new_dest_face_canvas_area\n",
    "    #for demo, select triangle 10\n",
    "#     if i==10:\n",
    "#         cv2.imshow(\"11: pasting the triangle at destination canvas\",destination_image_canvas)    \n",
    "    \n",
    "# cv2.imshow(\"12: the completed destination canvas\", destination_image_canvas)    \n",
    "    \n",
    "    \n",
    "#Swap by Masking the Destination face and placing the newly created face\n",
    "#######################################################################\n",
    "# create a new canvas for final image in exactly the same size of destination image\n",
    "final_destination_canvas = np.zeros_like(destination_image_grayscale)\n",
    "#cv2.imshow(\"13.1: the final destination canvas\", final_destination_canvas)     \n",
    "\n",
    "#create the destination face mask\n",
    "final_destination_face_mask = cv2.fillConvexPoly(final_destination_canvas, destination_face_convexhull, 255)\n",
    "#cv2.imshow(\"13.2: the final destination face mask\", final_destination_face_mask)     \n",
    "    \n",
    "#invert the face mask color\n",
    "final_destination_canvas = cv2.bitwise_not(final_destination_face_mask)    \n",
    "#cv2.imshow(\"13.3: the inverted final destination face mask\", final_destination_face_mask)      \n",
    "    \n",
    "#mask destination face\n",
    "destination_face_masked = cv2.bitwise_and(destination_image, destination_image, mask=final_destination_canvas)  \n",
    "#cv2.imshow(\"13.4: the destination_face_masked\", destination_face_masked)\n",
    "\n",
    "#place new face into destination image\n",
    "destination_with_face = cv2.add(destination_face_masked,destination_image_canvas)      \n",
    "#cv2.imshow(\"13.5: the destination_with_face\", destination_with_face)  \n",
    "    \n",
    "    \n",
    "    \n",
    "#Do seamless clone to make the attachment blend with the sorrounding pixels\n",
    "###########################################################################   \n",
    "#finding the center point of the destination covex hull\n",
    "(x,y,w,h) = cv2.boundingRect(destination_face_convexhull)  \n",
    "destination_face_center_point = (int((x+x+w)/2), int((y+y+h)/2))\n",
    "\n",
    "\n",
    "#do the seamless clone   \n",
    "seamlesscloned_face = cv2.seamlessClone(destination_with_face, destination_image, final_destination_face_mask, destination_face_center_point, cv2.NORMAL_CLONE)\n",
    "\n",
    "cv2.imshow(\"14: seamlesscloned_face\", seamlesscloned_face)  \n",
    "\n",
    "#close all imshow windows when any key is pressed\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8deb6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
